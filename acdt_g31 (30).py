# -*- coding: utf-8 -*-
"""acdt_g31

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F5fm0D95_3CLMpKv3LVVCJCWz4Vwmcv_
"""

# ============================================
# ACDT G31 – GERD(2020) → GDP(2022/2023)
# Full Regressions (Model 1–4) + Viz + Summary
# - 2020→2022, 2020→2023 고정 회귀(Colab 스펙)
# ============================================

import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf

st.set_page_config(page_title="ACDT G31 – GERD→GDP (Year-paired)", layout="wide")

# ---------- CSV 파일명 ----------
DATA_FILE = "ACDT_final_dataset.csv"   # 레포 루트에 위치

# ---------- 1행(Indicator) 라벨(Colab 기준과 정확히 일치해야 함) ----------
GDP_NAME  = "Real GDP (billion USD, PPP-based, Chain-weighted, 2020 base year)"
GERD_NAME = "Gross Domestic Expenditure on R&D (GERD) (current PPP USD)"

MEDIATOR_NAMES = [
    "Resident Patent Applications",
    "Non-Resident Patent Applications",
    "R&D Researchers per Million People",
    "High-tech Export Share (% of Manufactured Exports)",
    "Business R&D Personnel (FTE)",
]
CONFOUNDER_NAMES = ["GDP per Capita", "Labor Force Size"]
MODERATOR_NAMES  = ["Government-financed BERD (%)", "Business-financed BERD (%)"]

# 고정 연도쌍(Colab 스펙)
X_YEAR = 2020
Y_YEARS = [2022, 2023]


# ---------- 유틸: 안전한 CSV 파서 ----------
def read_as_multiindex(path: str) -> pd.DataFrame:
    """
    CSV를 읽어 0행=Year, 1행=Indicator 로 MultiIndex 컬럼 구성.
    - 한 열 CSV(텍스트)일 때 자동으로 구분자(, / \t / ;) 감지 후 split
    - 숫자 정제(Series-only .str) 후 float 변환
    - (Indicator, Year) 중복열은 행별 평균으로 통합
    """
    # 1) 다양한 인코딩 시도
    raw, last_err = None, None
    for enc in ("utf-8-sig", "cp949"):
        try:
            raw = pd.read_csv(path, header=None, encoding=enc, engine="python")
            break
        except Exception as e:
            last_err = e
    if raw is None:
        raise RuntimeError(f"CSV read failed: {last_err}")

    # 2) 한 열 CSV일 때 안전 분할
    if raw.shape[1] == 1:
        try:
            cell0 = raw.iloc[0, 0]
            cell0_str = "" if pd.isna(cell0) else str(cell0)
            seps = [",", "\t", ";"]
            detected = next((sep for sep in seps if sep in cell0_str), None)
            if detected:
                s = raw.iloc[:, 0].astype(str)                 # 반드시 Series로 변환
                raw = s.str.split(detected, expand=True)        # Series.str.split만 사용
        except Exception:
            pass  # 분할 실패 시 원본 유지

    # 3) 0행=연도, 1행=지표명
    years = raw.iloc[0].astype(str).str.strip().values
    names = raw.iloc[1].astype(str).str.strip().values
    df = raw.iloc[2:].copy()

    # 4) MultiIndex 컬럼
    df.columns = pd.MultiIndex.from_arrays([names, years], names=["Indicator", "Year"])

    # 5) 숫자 정제(항상 Series에서만 .str 사용)
    def clean_series(s: pd.Series) -> pd.Series:
        s = s.astype(str)
        s = s.str.replace(",", "", regex=False)
        s = s.str.replace(r"[^0-9eE+\-\.]", "", regex=True)
        return pd.to_numeric(s, errors="coerce")

    for j in range(df.shape[1]):                  # 위치 기반 → Series만 다룸
        df.iloc[:, j] = clean_series(df.iloc[:, j])

    # 6) Year 숫자화(가능 시)
    try:
        new_cols = []
        for (ind, yr) in df.columns:
            y = int(float(yr)) if str(yr).replace(".", "", 1).isdigit() else yr
            new_cols.append((ind, y))
        df.columns = pd.MultiIndex.from_tuples(new_cols, names=["Indicator", "Year"])
    except Exception:
        pass

    # 7) (Indicator,Year) 중복열 → 행별 평균으로 통합
    dups = df.columns.duplicated(keep=False)
    if dups.any():
        df = df.T.groupby(level=["Indicator", "Year"]).mean(numeric_only=True).T

    df.index = pd.RangeIndex(len(df))
    return df


def s_at(df_mi: pd.DataFrame, name: str, year) -> pd.Series:
    """지표@연도 Series 안전 추출(없으면 NaN)."""
    try:
        if (name in df_mi.columns.get_level_values(0)) and (year in df_mi.loc[:, name].columns):
            return df_mi.loc[:, (name, year)]
    except KeyError:
        pass
    return pd.Series([np.nan] * len(df_mi), index=df_mi.index)


def build_pair_dataset(df_mi: pd.DataFrame, x_year: int, y_year: int) -> pd.DataFrame:
    """GERD(x_year) → GDP(y_year) 회귀용 데이터 구성 + 로그 변환."""
    out = pd.DataFrame(index=df_mi.index)
    out["GERD"] = s_at(df_mi, GERD_NAME, x_year)
    out["GDP"]  = s_at(df_mi, GDP_NAME,  y_year)
    for v in CONFOUNDER_NAMES + MEDIATOR_NAMES + MODERATOR_NAMES:
        out[v] = s_at(df_mi, v, y_year)

    out["ln_X"] = np.log(out["GERD"].replace({0: np.nan}))
    out["ln_Y"] = np.log(out["GDP"].replace({0: np.nan}))

    return out.dropna(subset=["ln_X", "ln_Y"]).reset_index(drop=True)


def run_models(df_reg: pd.DataFrame):
    """Model1~4 실행 + 비교표 반환."""
    confs = [c for c in CONFOUNDER_NAMES if c in df_reg.columns]
    meds  = [m for m in MEDIATOR_NAMES  if m in df_reg.columns]
    mods  = [m for m in MODERATOR_NAMES if m in df_reg.columns]

    # M1: 단순 회귀
    m1 = smf.ols("ln_Y ~ ln_X", data=df_reg).fit()

    # M2: + confounders
    rhs2 = "ln_X" + ((" + " + " + ".join([f'Q(\"{c}\")' for c in confs])) if confs else "")
    m2 = smf.ols(f"ln_Y ~ {rhs2}", data=df_reg).fit()

    # M3: + mediators
    rhs3 = rhs2 + ((" + " + " + ".join([f'Q(\"{m}\")' for m in meds])) if meds else "")
    m3 = smf.ols(f"ln_Y ~ {rhs3}", data=df_reg).fit()

    # M4: + moderators (interaction)
    inter = " + ".join([f'ln_X * Q(\"{mo}\")' for mo in mods]) if mods else ""
    rhs4 = rhs3 if not inter else f"{rhs3} + {inter}"
    m4 = smf.ols(f"ln_Y ~ {rhs4}", data=df_reg).fit()

    def pick(mod, key="ln_X"):
        return mod.params.get(key, np.nan), mod.pvalues.get(key, np.nan), mod.rsquared_adj

    rows = []
    for label, mod in [("M1: lnY~lnX", m1), ("M2:+conf", m2), ("M3:+med", m3), ("M4:+mods", m4)]:
        beta, pval, adjr2 = pick(mod, "ln_X")
        rows.append([label, beta, pval, adjr2])

    summary = pd.DataFrame(rows, columns=["Model", "β(ln_X)", "p(ln_X)", "Adj.R²"]).round(4)
    return {"M1": m1, "M2": m2, "M3": m3, "M4": m4}, summary


# ---------- 앱 ----------
st.title("📈 GERD(2020) → GDP(2022/2023) – Full Regressions (Model 1–4)")

try:
    df_mi = read_as_multiindex(DATA_FILE)
except Exception as e:
    st.error(f"Error loading data: {e}")
    st.stop()

st.success("✅ Dataset loaded (Row0=Year, Row1=Indicator → MultiIndex & cleaned).")

# ----- 전체 숫자 분포 & 상관 히트맵 -----
st.header("📊 Distributions & Correlations")
num_df = df_mi.copy()
num_df.columns = [f"{a} [{b}]" for a, b in num_df.columns]   # MultiIndex → 평평한 이름
if not num_df.empty:
    st.write(num_df.describe().T)
    try:
        fig_corr, ax_corr = plt.subplots(figsize=(12, 7))
        sns.heatmap(num_df.corr(), cmap="coolwarm", center=0, ax=ax_corr)
        ax_corr.set_title("Correlation Heatmap")
        st.pyplot(fig_corr)
    except Exception:
        st.info("Correlation heatmap skipped (insufficient numeric columns).")

# ----- 두 연도쌍 회귀 (2020→2022, 2020→2023) -----
for yyr in Y_YEARS:
    st.markdown("---")
    st.header(f"🧮 Pair: GERD({X_YEAR}) → GDP({yyr})")

    df_reg = build_pair_dataset(df_mi, X_YEAR, yyr)
    if df_reg.empty:
        st.warning("No valid observations after cleaning for this pair (ln_X/ln_Y).")
        continue

    st.subheader("📋 Regression dataset (preview)")
    st.dataframe(df_reg.head())

    # 산점도 + 회귀선
    st.subheader("📉 ln(GERD) vs ln(GDP)")
    fig_sc, ax_sc = plt.subplots(figsize=(7, 5))
    sns.regplot(x="ln_X", y="ln_Y", data=df_reg, scatter_kws={"alpha":0.6}, ax=ax_sc)
    ax_sc.set_xlabel(f"ln GERD ({X_YEAR})")
    ax_sc.set_ylabel(f"ln GDP ({yyr})")
    st.pyplot(fig_sc)

    # Model 1–4
    models, table = run_models(df_reg)
    st.subheader("📘 Model Comparison")
    st.dataframe(table)

    fig_r2, ax_r2 = plt.subplots(figsize=(6, 4))
    sns.barplot(x="Model", y="Adj.R²", data=table, ax=ax_r2)
    ax_r2.set_ylim(0, max(table["Adj.R²"]) * 1.1 if len(table) else 1)
    ax_r2.set_title("Adjusted R² across models")
    st.pyplot(fig_r2)

    with st.expander("Full regression summaries"):
        for k, m in models.items():
            st.markdown(f"**{k}**")
            st.text(m.summary())

# ----- 해석 섹션 -----
st.markdown("""
### 🧩 Interpretation
- **Model 1**: GERD와 GDP 간 기본 탄력성(ln-ln).
- **Model 2**: 교란변수(1인당 GDP, 노동력 규모) 통제 → lnGERD 계수 변화로 **혼란효과** 점검.
- **Model 3**: 특허·연구인력·하이테크수출·기업R&D인력 추가 → lnGERD 계수 감소/유의 변화 시 **매개효과** 시사.
- **Model 4**: 정부/민간 BERD 비중과의 상호작용 → 상호작용 p<0.05면 **조절효과** 유의.
""")