# -*- coding: utf-8 -*-
"""acdt_g31

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F5fm0D95_3CLMpKv3LVVCJCWz4Vwmcv_
"""

# ============================================
# ACDT G31 â€“ GERD(2020) â†’ GDP(2022/2023)
# Full Regressions (Model 1â€“4) + Viz + Summary
# - 2020â†’2022, 2020â†’2023 ê³ ì • íšŒê·€(Colab ìŠ¤í™)
# ============================================

import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf

st.set_page_config(page_title="ACDT G31 â€“ GERDâ†’GDP (Year-paired)", layout="wide")

# ---------- CSV íŒŒì¼ëª… ----------
DATA_FILE = "ACDT_final_dataset.csv"   # ë ˆí¬ ë£¨íŠ¸ì— ìœ„ì¹˜

# ---------- 1í–‰(Indicator) ë¼ë²¨(Colab ê¸°ì¤€ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•¨) ----------
GDP_NAME  = "Real GDP (billion USD, PPP-based, Chain-weighted, 2020 base year)"
GERD_NAME = "Gross Domestic Expenditure on R&D (GERD) (current PPP USD)"

MEDIATOR_NAMES = [
    "Resident Patent Applications",
    "Non-Resident Patent Applications",
    "R&D Researchers per Million People",
    "High-tech Export Share (% of Manufactured Exports)",
    "Business R&D Personnel (FTE)",
]
CONFOUNDER_NAMES = ["GDP per Capita", "Labor Force Size"]
MODERATOR_NAMES  = ["Government-financed BERD (%)", "Business-financed BERD (%)"]

# ê³ ì • ì—°ë„ìŒ(Colab ìŠ¤í™)
X_YEAR = 2020
Y_YEARS = [2022, 2023]


# ---------- ìœ í‹¸: ì•ˆì „í•œ CSV íŒŒì„œ ----------
def read_as_multiindex(path: str) -> pd.DataFrame:
    """
    CSVë¥¼ ì½ì–´ 0í–‰=Year, 1í–‰=Indicator ë¡œ MultiIndex ì»¬ëŸ¼ êµ¬ì„±.
    - í•œ ì—´ CSV(í…ìŠ¤íŠ¸)ì¼ ë•Œ ìë™ìœ¼ë¡œ êµ¬ë¶„ì(, / \t / ;) ê°ì§€ í›„ split
    - ìˆ«ì ì •ì œ(Series-only .str) í›„ float ë³€í™˜
    - (Indicator, Year) ì¤‘ë³µì—´ì€ í–‰ë³„ í‰ê· ìœ¼ë¡œ í†µí•©
    """
    # 1) ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„
    raw, last_err = None, None
    for enc in ("utf-8-sig", "cp949"):
        try:
            raw = pd.read_csv(path, header=None, encoding=enc, engine="python")
            break
        except Exception as e:
            last_err = e
    if raw is None:
        raise RuntimeError(f"CSV read failed: {last_err}")

    # 2) í•œ ì—´ CSVì¼ ë•Œ ì•ˆì „ ë¶„í• 
    if raw.shape[1] == 1:
        try:
            cell0 = raw.iloc[0, 0]
            cell0_str = "" if pd.isna(cell0) else str(cell0)
            seps = [",", "\t", ";"]
            detected = next((sep for sep in seps if sep in cell0_str), None)
            if detected:
                s = raw.iloc[:, 0].astype(str)                 # ë°˜ë“œì‹œ Seriesë¡œ ë³€í™˜
                raw = s.str.split(detected, expand=True)        # Series.str.splitë§Œ ì‚¬ìš©
        except Exception:
            pass  # ë¶„í•  ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€

    # 3) 0í–‰=ì—°ë„, 1í–‰=ì§€í‘œëª…
    years = raw.iloc[0].astype(str).str.strip().values
    names = raw.iloc[1].astype(str).str.strip().values
    df = raw.iloc[2:].copy()

    # 4) MultiIndex ì»¬ëŸ¼
    df.columns = pd.MultiIndex.from_arrays([names, years], names=["Indicator", "Year"])

    # 5) ìˆ«ì ì •ì œ(í•­ìƒ Seriesì—ì„œë§Œ .str ì‚¬ìš©)
    def clean_series(s: pd.Series) -> pd.Series:
        s = s.astype(str)
        s = s.str.replace(",", "", regex=False)
        s = s.str.replace(r"[^0-9eE+\-\.]", "", regex=True)
        return pd.to_numeric(s, errors="coerce")

    for j in range(df.shape[1]):                  # ìœ„ì¹˜ ê¸°ë°˜ â†’ Seriesë§Œ ë‹¤ë£¸
        df.iloc[:, j] = clean_series(df.iloc[:, j])

    # 6) Year ìˆ«ìí™”(ê°€ëŠ¥ ì‹œ)
    try:
        new_cols = []
        for (ind, yr) in df.columns:
            y = int(float(yr)) if str(yr).replace(".", "", 1).isdigit() else yr
            new_cols.append((ind, y))
        df.columns = pd.MultiIndex.from_tuples(new_cols, names=["Indicator", "Year"])
    except Exception:
        pass

    # 7) (Indicator,Year) ì¤‘ë³µì—´ â†’ í–‰ë³„ í‰ê· ìœ¼ë¡œ í†µí•©
    dups = df.columns.duplicated(keep=False)
    if dups.any():
        df = df.T.groupby(level=["Indicator", "Year"]).mean(numeric_only=True).T

    df.index = pd.RangeIndex(len(df))
    return df


def s_at(df_mi: pd.DataFrame, name: str, year) -> pd.Series:
    """ì§€í‘œ@ì—°ë„ Series ì•ˆì „ ì¶”ì¶œ(ì—†ìœ¼ë©´ NaN)."""
    try:
        if (name in df_mi.columns.get_level_values(0)) and (year in df_mi.loc[:, name].columns):
            return df_mi.loc[:, (name, year)]
    except KeyError:
        pass
    return pd.Series([np.nan] * len(df_mi), index=df_mi.index)


def build_pair_dataset(df_mi: pd.DataFrame, x_year: int, y_year: int) -> pd.DataFrame:
    """GERD(x_year) â†’ GDP(y_year) íšŒê·€ìš© ë°ì´í„° êµ¬ì„± + ë¡œê·¸ ë³€í™˜."""
    out = pd.DataFrame(index=df_mi.index)
    out["GERD"] = s_at(df_mi, GERD_NAME, x_year)
    out["GDP"]  = s_at(df_mi, GDP_NAME,  y_year)
    for v in CONFOUNDER_NAMES + MEDIATOR_NAMES + MODERATOR_NAMES:
        out[v] = s_at(df_mi, v, y_year)

    out["ln_X"] = np.log(out["GERD"].replace({0: np.nan}))
    out["ln_Y"] = np.log(out["GDP"].replace({0: np.nan}))

    return out.dropna(subset=["ln_X", "ln_Y"]).reset_index(drop=True)


def run_models(df_reg: pd.DataFrame):
    """Model1~4 ì‹¤í–‰ + ë¹„êµí‘œ ë°˜í™˜."""
    confs = [c for c in CONFOUNDER_NAMES if c in df_reg.columns]
    meds  = [m for m in MEDIATOR_NAMES  if m in df_reg.columns]
    mods  = [m for m in MODERATOR_NAMES if m in df_reg.columns]

    # M1: ë‹¨ìˆœ íšŒê·€
    m1 = smf.ols("ln_Y ~ ln_X", data=df_reg).fit()

    # M2: + confounders
    rhs2 = "ln_X" + ((" + " + " + ".join([f'Q(\"{c}\")' for c in confs])) if confs else "")
    m2 = smf.ols(f"ln_Y ~ {rhs2}", data=df_reg).fit()

    # M3: + mediators
    rhs3 = rhs2 + ((" + " + " + ".join([f'Q(\"{m}\")' for m in meds])) if meds else "")
    m3 = smf.ols(f"ln_Y ~ {rhs3}", data=df_reg).fit()

    # M4: + moderators (interaction)
    inter = " + ".join([f'ln_X * Q(\"{mo}\")' for mo in mods]) if mods else ""
    rhs4 = rhs3 if not inter else f"{rhs3} + {inter}"
    m4 = smf.ols(f"ln_Y ~ {rhs4}", data=df_reg).fit()

    def pick(mod, key="ln_X"):
        return mod.params.get(key, np.nan), mod.pvalues.get(key, np.nan), mod.rsquared_adj

    rows = []
    for label, mod in [("M1: lnY~lnX", m1), ("M2:+conf", m2), ("M3:+med", m3), ("M4:+mods", m4)]:
        beta, pval, adjr2 = pick(mod, "ln_X")
        rows.append([label, beta, pval, adjr2])

    summary = pd.DataFrame(rows, columns=["Model", "Î²(ln_X)", "p(ln_X)", "Adj.RÂ²"]).round(4)
    return {"M1": m1, "M2": m2, "M3": m3, "M4": m4}, summary


# ---------- ì•± ----------
st.title("ğŸ“ˆ GERD(2020) â†’ GDP(2022/2023) â€“ Full Regressions (Model 1â€“4)")

try:
    df_mi = read_as_multiindex(DATA_FILE)
except Exception as e:
    st.error(f"Error loading data: {e}")
    st.stop()

st.success("âœ… Dataset loaded (Row0=Year, Row1=Indicator â†’ MultiIndex & cleaned).")

# ----- ì „ì²´ ìˆ«ì ë¶„í¬ & ìƒê´€ íˆíŠ¸ë§µ -----
st.header("ğŸ“Š Distributions & Correlations")
num_df = df_mi.copy()
num_df.columns = [f"{a} [{b}]" for a, b in num_df.columns]   # MultiIndex â†’ í‰í‰í•œ ì´ë¦„
if not num_df.empty:
    st.write(num_df.describe().T)
    try:
        fig_corr, ax_corr = plt.subplots(figsize=(12, 7))
        sns.heatmap(num_df.corr(), cmap="coolwarm", center=0, ax=ax_corr)
        ax_corr.set_title("Correlation Heatmap")
        st.pyplot(fig_corr)
    except Exception:
        st.info("Correlation heatmap skipped (insufficient numeric columns).")

# ----- ë‘ ì—°ë„ìŒ íšŒê·€ (2020â†’2022, 2020â†’2023) -----
for yyr in Y_YEARS:
    st.markdown("---")
    st.header(f"ğŸ§® Pair: GERD({X_YEAR}) â†’ GDP({yyr})")

    df_reg = build_pair_dataset(df_mi, X_YEAR, yyr)
    if df_reg.empty:
        st.warning("No valid observations after cleaning for this pair (ln_X/ln_Y).")
        continue

    st.subheader("ğŸ“‹ Regression dataset (preview)")
    st.dataframe(df_reg.head())

    # ì‚°ì ë„ + íšŒê·€ì„ 
    st.subheader("ğŸ“‰ ln(GERD) vs ln(GDP)")
    fig_sc, ax_sc = plt.subplots(figsize=(7, 5))
    sns.regplot(x="ln_X", y="ln_Y", data=df_reg, scatter_kws={"alpha":0.6}, ax=ax_sc)
    ax_sc.set_xlabel(f"ln GERD ({X_YEAR})")
    ax_sc.set_ylabel(f"ln GDP ({yyr})")
    st.pyplot(fig_sc)

    # Model 1â€“4
    models, table = run_models(df_reg)
    st.subheader("ğŸ“˜ Model Comparison")
    st.dataframe(table)

    fig_r2, ax_r2 = plt.subplots(figsize=(6, 4))
    sns.barplot(x="Model", y="Adj.RÂ²", data=table, ax=ax_r2)
    ax_r2.set_ylim(0, max(table["Adj.RÂ²"]) * 1.1 if len(table) else 1)
    ax_r2.set_title("Adjusted RÂ² across models")
    st.pyplot(fig_r2)

    with st.expander("Full regression summaries"):
        for k, m in models.items():
            st.markdown(f"**{k}**")
            st.text(m.summary())

# ----- í•´ì„ ì„¹ì…˜ -----
st.markdown("""
### ğŸ§© Interpretation
- **Model 1**: GERDì™€ GDP ê°„ ê¸°ë³¸ íƒ„ë ¥ì„±(ln-ln).
- **Model 2**: êµë€ë³€ìˆ˜(1ì¸ë‹¹ GDP, ë…¸ë™ë ¥ ê·œëª¨) í†µì œ â†’ lnGERD ê³„ìˆ˜ ë³€í™”ë¡œ **í˜¼ë€íš¨ê³¼** ì ê²€.
- **Model 3**: íŠ¹í—ˆÂ·ì—°êµ¬ì¸ë ¥Â·í•˜ì´í…Œí¬ìˆ˜ì¶œÂ·ê¸°ì—…R&Dì¸ë ¥ ì¶”ê°€ â†’ lnGERD ê³„ìˆ˜ ê°ì†Œ/ìœ ì˜ ë³€í™” ì‹œ **ë§¤ê°œíš¨ê³¼** ì‹œì‚¬.
- **Model 4**: ì •ë¶€/ë¯¼ê°„ BERD ë¹„ì¤‘ê³¼ì˜ ìƒí˜¸ì‘ìš© â†’ ìƒí˜¸ì‘ìš© p<0.05ë©´ **ì¡°ì ˆíš¨ê³¼** ìœ ì˜.
""")