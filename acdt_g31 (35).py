# -*- coding: utf-8 -*-
"""acdt_g31

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F5fm0D95_3CLMpKv3LVVCJCWz4Vwmcv_
"""

# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf
import warnings

warnings.filterwarnings("ignore")

st.set_page_config(page_title="ACDT G31 – GERD(2020) → GDP(2023)", layout="wide")
st.title("📈 GERD(2020) → GDP(2023) – Full Regression Models (1–4)")

DATA_FILE = "ACDT_final_dataset.csv"

GDP_NAME = "Real GDP (billion USD, PPP-based, Chain-weighted, 2020 base year)"
GERD_NAME = "Gross Domestic Expenditure on R&D (GERD) (current PPP USD)"
MEDIATOR_NAMES = [
    "Resident Patent Applications",
    "Non-Resident Patent Applications",
    "R&D Researchers per Million People",
    "High-tech Export Share (% of Manufactured Exports)",
    "Business R&D Personnel (FTE)"
]
CONFOUNDER_NAMES = ["GDP per Capita", "Labor Force Size"]
MODERATOR_NAMES = ["Government-financed BERD (%)", "Business-financed BERD (%)"]

X_YEAR = 2020
Y_YEAR = 2023

@st.cache_data
def read_as_multiindex(path: str) -> pd.DataFrame:
    raw, last_err = None, None
    for enc in ("utf-8-sig", "cp949"):
        try:
            raw = pd.read_csv(path, header=None, encoding=enc, engine="python")
            break
        except Exception as e:
            last_err = e
    if raw is None:
        raise RuntimeError(f"CSV read failed: {last_err}")

    # 단일 컬럼 CSV일 때만 문자열 분할
    if int(raw.shape[1]) == 1:
        try:
            n = int(min(5, len(raw)))
            sample_text = "\n".join(raw.iloc[:n, 0].astype(str).tolist())
            seps = [",", "\t", ";"]
            found_sep = None
            for s in seps:
                if sample_text.find(s) != -1:
                    found_sep = s
                    break
            if found_sep is not None:
                s = raw.iloc[:, 0].astype(str)
                raw = s.str.split(found_sep, expand=True)
        except Exception:
            pass

    years = raw.iloc[0].astype(str).str.strip().values
    names = raw.iloc[1].astype(str).str.strip().values
    df = raw.iloc[2:].copy()
    df.columns = pd.MultiIndex.from_arrays([names, years], names=["Indicator", "Year"])
    def clean_series(s: pd.Series) -> pd.Series:
        s = s.astype(str)
        s = s.str.replace(",", "", regex=False)
        s = s.str.replace(r"[^0-9eE+\-\.]", "", regex=True)
        return pd.to_numeric(s, errors="coerce")
    for j in range(df.shape[1]):
        df.iloc[:, j] = clean_series(df.iloc[:, j])

    try:
        new_cols = []
        for ind, yr in df.columns:
            ystr = str(yr)
            if ystr.replace(".", "", 1).isdigit():
                yv = int(float(ystr))
            else:
                yv = yr
            new_cols.append((ind, yv))
        df.columns = pd.MultiIndex.from_tuples(new_cols, names=["Indicator", "Year"])
    except Exception:
        pass

    if df.columns.duplicated(keep=False).any():
        df = df.T.groupby(level=["Indicator", "Year"]).mean(numeric_only=True).T
        df.index = pd.RangeIndex(len(df))
    return df

def s_at(df_mi: pd.DataFrame, name: str, year) -> pd.Series:
    lvl0 = df_mi.columns.get_level_values(0)
    if name in set(lvl0):
        sub = df_mi.loc[:, name]
        if year in set(sub.columns):
            return df_mi.loc[:, (name, year)]
    return pd.Series([np.nan] * len(df_mi), index=df_mi.index)

def build_pair_dataset(df_mi: pd.DataFrame, x_year: int, y_year: int) -> pd.DataFrame:
    out = pd.DataFrame(index=df_mi.index)
    out["GERD"] = s_at(df_mi, GERD_NAME, x_year)
    out["GDP"] = s_at(df_mi, GDP_NAME, y_year)
    for v in CONFOUNDER_NAMES + MEDIATOR_NAMES + MODERATOR_NAMES:
        out[v] = s_at(df_mi, v, y_year)
    out["ln_X"] = np.log(out["GERD"].replace({0: np.nan}))
    out["ln_Y"] = np.log(out["GDP"].replace({0: np.nan}))
    return out.dropna(subset=["ln_X", "ln_Y"]).reset_index(drop=True)

def run_models(df_reg: pd.DataFrame):
    confs = [c for c in CONFOUNDER_NAMES if c in df_reg.columns]
    meds = [m for m in MEDIATOR_NAMES if m in df_reg.columns]
    mods = [m for m in MODERATOR_NAMES if m in df_reg.columns]
    m1 = smf.ols("ln_Y ~ ln_X", data=df_reg).fit()
    rhs2 = "ln_X" + ((" + " + " + ".join([f'Q(\"{c}\")' for c in confs])) if confs else "")
    m2 = smf.ols(f"ln_Y ~ {rhs2}", data=df_reg).fit()
    rhs3 = rhs2 + ((" + " + " + ".join([f'Q(\"{m}\")' for m in meds])) if meds else "")
    m3 = smf.ols(f"ln_Y ~ {rhs3}", data=df_reg).fit()
    inter = " + ".join([f'ln_X * Q(\"{mo}\")' for mo in mods]) if mods else ""
    rhs4 = rhs3 if not inter else f"{rhs3} + {inter}"
    m4 = smf.ols(f"ln_Y ~ {rhs4}", data=df_reg).fit()
    def pick(mod, key="ln_X"):
        return mod.params.get(key, np.nan), mod.pvalues.get(key, np.nan), mod.rsquared_adj
    rows = []
    for label, mod in [("M1: lnY~lnX", m1), ("M2:+conf", m2), ("M3:+med", m3), ("M4:+mods", m4)]:
        beta, pval, adjr2 = pick(mod, "ln_X")
        rows.append([label, beta, pval, adjr2])
    summary = pd.DataFrame(rows, columns=["Model", "β(ln_X)", "p(ln_X)", "Adj.R²"]).round(4)
    return {"M1": m1, "M2": m2, "M3": m3, "M4": m4}, summary

try:
    df_mi = read_as_multiindex(DATA_FILE)
    st.success("✅ Dataset loaded & cleaned (Row0=Year / Row1=Indicator).")
except Exception as e:
    st.error(f"Error loading data: {e}")
    st.stop()

st.header("📊 Distributions & Correlations")
flat = df_mi.copy()
flat.columns = [f"{a} [{b}]" for a, b in flat.columns]
num_only = flat.select_dtypes(include=np.number)
if not num_only.empty:
    st.write(num_only.describe().T)
    try:
        fig_corr, ax_corr = plt.subplots(figsize=(12, 7))
        sns.heatmap(num_only.corr(), cmap="coolwarm", center=0, ax=ax_corr)
        ax_corr.set_title("Correlation Heatmap")
        st.pyplot(fig_corr)
    except Exception:
        st.info("Correlation heatmap skipped.")

st.markdown("---")
st.header(f"🧮 Pair: GERD({X_YEAR}) → GDP({Y_YEAR}) (All others at {Y_YEAR})")
df_reg = build_pair_dataset(df_mi, X_YEAR, Y_YEAR)
if df_reg.empty:
    st.warning("No valid observations for this pair after cleaning (ln_X/ln_Y). Check labels/years.")
    st.stop()
st.subheader("📋 Regression dataset (preview)")
st.dataframe(df_reg.head())
st.subheader("📉 ln(GERD) vs ln(GDP)")
fig_sc, ax_sc = plt.subplots(figsize=(7, 5))
sns.regplot(x="ln_X", y="ln_Y", data=df_reg, scatter_kws={"alpha": 0.6}, ax=ax_sc)
ax_sc.set_xlabel(f"ln GERD ({X_YEAR})")
ax_sc.set_ylabel(f"ln GDP ({Y_YEAR})")
st.pyplot(fig_sc)
models, table = run_models(df_reg)
st.subheader("📘 Model Comparison")
st.dataframe(table)
fig_r2, ax_r2 = plt.subplots(figsize=(6, 4))
sns.barplot(x="Model", y="Adj.R²", data=table, ax=ax_r2)
ymax = float(table["Adj.R²"].max()) if len(table) > 0 else 1.0
ax_r2.set_ylim(0, max(0.1, ymax) * 1.1)
ax_r2.set_title("Adjusted R² across models")
st.pyplot(fig_r2)
with st.expander("Full regression summaries"):
    for k, m in models.items():
        st.markdown(f"**{k}**")
        st.text(m.summary())
st.markdown("""
### 🧩 Interpretation (2020→2023)
- **Model 1**: lnGERD(2020) → lnGDP(2023) 기본 탄력성.
- **Model 2**: GDP per Capita, Labor Force(2023) 통제로 **혼란효과** 점검(lnGERD 계수 변화).
- **Model 3**: 특허·연구인력·하이테크수출·기업R&D인력(2023) 포함 → lnGERD 계수 감소/유의성 변화 시 **매개효과** 시사.
- **Model 4**: Government/Business-financed BERD(2023) 상호작용 p<0.05면 **조절효과** 유의.
""")