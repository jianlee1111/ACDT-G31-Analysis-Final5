# -*- coding: utf-8 -*-
"""acdt_g31

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F5fm0D95_3CLMpKv3LVVCJCWz4Vwmcv_
"""

# ================================================================
# üìä ACDT Group 31 Final Streamlit Dashboard (Ultimate v8)
# ================================================================
# - Handles CSV where 1st row = years, 2nd row = variable names
# - Cleans + converts mixed data, removes symbols
# - Performs log-transform, correlation, and Model 1‚Äì4 regressions
# - Shows variable distributions & interpretive summaries
# ================================================================

import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf

st.set_page_config(page_title="ACDT Group 31 ‚Äì GERD & GDP Full Analysis", layout="wide")

# ================================================================
# 1Ô∏è‚É£ Load and preprocess data (robust for your CSV structure)
# ================================================================
@st.cache_data
def load_and_clean_data():
    try:
        # Auto-detect delimiter and encoding
        df_raw = pd.read_csv(
            "ACDT_final_dataset.csv",
            header=None,
            sep=None,               # automatic delimiter detection (comma, tab, semicolon)
            engine="python",
            encoding="utf-8-sig",
            on_bad_lines="skip"
        )

        # Sanity check: must have at least 2 rows (header + data)
        if df_raw.shape[0] < 2:
            st.error("‚ùå The file seems to have fewer than 2 rows.")
            return pd.DataFrame()

        # Use 2nd row as header
        df = df_raw.copy()
        df.columns = df_raw.iloc[1].astype(str).apply(lambda x: x.strip())
        df = df.drop([0, 1]).reset_index(drop=True)

        # Clean all numeric columns
        for col in df.columns:
            df[col] = (
                df[col]
                .astype(str)
                .str.replace(",", "", regex=False)
                .str.replace(r"[^0-9eE+.-]", "", regex=True)
            )
            df[col] = pd.to_numeric(df[col], errors="coerce")

        # Drop empty rows
        df.dropna(how="all", inplace=True)

        # Clean column names (remove hidden unicode chars)
        df.columns = (
            df.columns.str.strip()
            .str.replace("\ufeff", "")
            .str.replace("\xa0", "")
            .str.replace("\u200b", "")
        )

        # Rename based on keyword detection
        rename_map = {}
        for col in df.columns:
            c = col.lower().replace("&", "and").replace("\n", " ")
            if "real gdp" in c or ("gdp" in c and "real" in c):
                rename_map[col] = "Real_GDP"
            elif "gerd" in c or "gross domestic expenditure" in c:
                rename_map[col] = "GERD"

        df.rename(columns=rename_map, inplace=True)

        # If Real_GDP or GERD not found ‚Üí stop
        if "Real_GDP" not in df.columns or "GERD" not in df.columns:
            st.warning("‚ö†Ô∏è Could not find 'Real_GDP' or 'GERD' columns after cleaning.")
            st.write("Detected columns:", df.columns.tolist())
            return pd.DataFrame()

        # Log-transform
        df["ln_GDP"] = np.log(df["Real_GDP"].replace(0, np.nan))
        df["ln_GERD"] = np.log(df["GERD"].replace(0, np.nan))

        return df

    except Exception as e:
        st.error(f"‚ùå Error during data load: {e}")
        return pd.DataFrame()


# ================================================================
# 2Ô∏è‚É£ Load Data and Preview
# ================================================================
st.title("üìà GERD and GDP Full Regression Dashboard ‚Äì ACDT Group 31")

df = load_and_clean_data()

if df.empty:
    st.error("‚ö†Ô∏è Dataset could not be loaded. Please verify structure or encoding.")
    st.stop()
else:
    st.success("‚úÖ Data successfully loaded and cleaned!")
    st.dataframe(df.head())


# ================================================================
# 3Ô∏è‚É£ Variable Distribution Visualization
# ================================================================
st.header("üìä Variable Distribution")

num_cols = df.select_dtypes(include=np.number).columns.tolist()
if num_cols:
    var = st.selectbox("Select variable to visualize:", num_cols)
    fig, ax = plt.subplots(1, 2, figsize=(12, 4))
    sns.histplot(df[var], kde=True, ax=ax[0], color="skyblue")
    ax[0].set_title(f"Distribution of {var}")
    sns.boxplot(x=df[var], ax=ax[1], color="salmon")
    ax[1].set_title(f"Boxplot of {var}")
    st.pyplot(fig)


# ================================================================
# 4Ô∏è‚É£ Correlation Heatmap
# ================================================================
st.header("üìà Correlation Matrix")
corr = df.select_dtypes(include=np.number).corr()
fig_corr, ax_corr = plt.subplots(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f", ax=ax_corr)
st.pyplot(fig_corr)


# ================================================================
# 5Ô∏è‚É£ Regression Models (Model 1‚Äì4)
# ================================================================
st.header("üßÆ Regression Models (Model 1‚Äì4)")

confounders = ["GDP per Capita", "Labor Force Size"]
mediators = [
    "Resident Patent Applications",
    "Non-Resident Patent Applications",
    "R&D Researchers per Million People",
    "High-tech Export Share (% of Manufactured Exports)",
    "Business R&D Personnel (FTE)",
]
moderators = ["Government-financed BERD (%)", "Business-financed BERD (%)"]

models = {}

try:
    # Model 1 ‚Äì Simple regression
    models["Model 1"] = smf.ols("ln_GDP ~ ln_GERD", data=df).fit()

    # Model 2 ‚Äì Add confounders
    valid_conf = [c for c in confounders if c in df.columns]
    if valid_conf:
        models["Model 2"] = smf.ols(
            f"ln_GDP ~ ln_GERD + {' + '.join([f'Q(\"{c}\")' for c in valid_conf])}",
            data=df,
        ).fit()
    else:
        models["Model 2"] = models["Model 1"]

    # Model 3 ‚Äì Add mediators
    valid_med = [m for m in mediators if m in df.columns]
    if valid_med:
        models["Model 3"] = smf.ols(
            f"ln_GDP ~ ln_GERD + {' + '.join([f'Q(\"{m}\")' for m in valid_med])}",
            data=df,
        ).fit()
    else:
        models["Model 3"] = models["Model 2"]

    # Model 4 ‚Äì Add moderators (interaction)
    valid_mod = [mo for mo in moderators if mo in df.columns]
    if valid_mod:
        interaction_terms = " + ".join([f"ln_GERD * Q(\"{mo}\")" for mo in valid_mod])
        models["Model 4"] = smf.ols(
            f"ln_GDP ~ {interaction_terms} + {' + '.join([f'Q(\"{m}\")' for m in valid_med])}",
            data=df,
        ).fit()
    else:
        models["Model 4"] = models["Model 3"]

    # ================================================================
    # 6Ô∏è‚É£ Model Comparison Summary
    # ================================================================
    summary_data = []
    for name, model in models.items():
        coef = model.params.get("ln_GERD", np.nan)
        pval = model.pvalues.get("ln_GERD", np.nan)
        adjr2 = model.rsquared_adj
        summary_data.append([name, round(coef, 4), round(pval, 4), round(adjr2, 4)])

    summary_df = pd.DataFrame(summary_data, columns=["Model", "Œ≤(ln_GERD)", "p-value", "Adj. R¬≤"])
    st.subheader("üìò Model Comparison Summary")
    st.dataframe(summary_df)

    # Visualization
    fig_r2, ax_r2 = plt.subplots()
    sns.barplot(x="Model", y="Adj. R¬≤", data=summary_df, palette="Blues_d", ax=ax_r2)
    ax_r2.set_title("Adjusted R¬≤ Across Models")
    st.pyplot(fig_r2)

    # ================================================================
    # 7Ô∏è‚É£ Interpretive Summary
    # ================================================================
    st.header("üß© Interpretive Summary")
    top_model = summary_df.loc[summary_df["Adj. R¬≤"].idxmax(), "Model"]
    st.markdown(f"**Best-fitting model:** {top_model}")

    st.markdown("""
    ### üîç Interpretation
    - **Model 1:** Baseline elasticity of GDP with respect to GERD
    - **Model 2:** Adds confounders (GDP per capita, labor force)
    - **Model 3:** Adds mediators (patents, researchers, exports, innovation)
    - **Model 4:** Adds moderators (R&D funding shares)

    **Result Summary:**
    GERD maintains a positive, statistically significant relationship with GDP across models.
    Mediators explain indirect innovation effects, while moderators adjust the policy intensity.
    """)

    with st.expander("üìÑ Full Regression Outputs"):
        for name, model in models.items():
            st.markdown(f"### {name}")
            st.text(model.summary())

except Exception as e:
    st.error(f"‚ùå Regression error: {e}")