# -*- coding: utf-8 -*-
"""acdt_g31

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F5fm0D95_3CLMpKv3LVVCJCWz4Vwmcv_
"""

# ============================================
# ACDT G31 â€“ GERD(2020) â†’ GDP(2023) Full App
# - CSV: row0 = Year, row1 = Indicator, row2~ = data
# - Safe parsing (no Series truth in if)
# - Models 1~4: confounder / mediator / moderator
# - Viz + Debug toggle
# ============================================

import warnings
warnings.filterwarnings("ignore")

import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf
from difflib import get_close_matches

st.set_page_config(page_title="ACDT G31 â€“ GERD(2020) â†’ GDP(2023)", layout="wide")

# =========================
# CONFIG
# =========================
DATA_FILE = "ACDT_final_dataset.csv"  # ì•±ê³¼ ê°™ì€ í´ë”ì— ë‘ì„¸ìš”.

# CSVì— ë“¤ì–´ìˆëŠ” â€œì •í™•í•œâ€ ì§€í‘œëª…ê³¼ 100% ì¼ì¹˜í•´ì•¼ í•¨(ê³µë°±/ê´„í˜¸/ê¸°í˜¸ í¬í•¨)
GDP_NAME  = "Real GDP (billion USD, PPP-based, Chain-weighted, 2020 base year)"
GERD_NAME = "Gross Domestic Expenditure on R&D (GERD) (current PPP USD)"

MEDIATOR_NAMES = [
    "Resident Patent Applications",
    "Non-Resident Patent Applications",
    "R&D Researchers per Million People",
    "High-tech Export Share (% of Manufactured Exports)",
    "Business R&D Personnel (FTE)",
]
CONFOUNDER_NAMES = [
    "GDP per Capita",
    "Labor Force Size",
]
MODERATOR_NAMES  = [
    "Government-financed BERD (%)",
    "Business-financed BERD (%)",
]

X_YEAR = 2020   # GERD ì—°ë„
Y_YEAR = 2023   # GDPì™€ ë‚˜ë¨¸ì§€ ë³€ìˆ˜ ì—°ë„

# =========================
# SAFE CSV PARSER (DEBUG)
# =========================
@st.cache_data
def read_as_multiindex_v2(path: str, debug: bool = False) -> pd.DataFrame:
    """CSV â†’ MultiIndex(Indicator, Year).
       - 0í–‰: Year / 1í–‰: Indicator
       - ë‹¨ì¼ ì»¬ëŸ¼ CSV ì‹œ ë¬¸ìì—´ë¡œ ë¶„ë¦¬ì ê°ì§€(split)
       - ìˆ«ì ì •ì œëŠ” Series ì „ìš© .str ì‚¬ìš©
       - ì¤‘ë³µ (Indicator,Year) í‰ê·  í†µí•©
    """
    raw, last_err = None, None
    for enc in ("utf-8-sig", "cp949"):
        try:
            raw = pd.read_csv(path, header=None, encoding=enc, engine="python")
            break
        except Exception as e:
            last_err = e
    if raw is None:
        raise RuntimeError(f"CSV read failed: {last_err}")

    # ë””ë²„ê·¸: ì›ì‹œ í—¤ë”/í”„ë¦¬ë·° ì¶œë ¥ í›„ ì¤‘ë‹¨
    if debug:
        st.subheader("ğŸ” DEBUG: Raw CSV (before parsing)")
        st.write("raw.shape:", raw.shape)
        r0 = raw.iloc[0]
        r1 = raw.iloc[1]
        if isinstance(r0, pd.DataFrame): r0 = r0.squeeze(axis=0)
        if isinstance(r1, pd.DataFrame): r1 = r1.squeeze(axis=0)
        st.write("row0 (years) â€” first 30:", r0.astype(str).tolist()[:30])
        st.write("row1 (indicator names) â€” first 30:", r1.astype(str).tolist()[:30])
        st.dataframe(raw.iloc[:6, :20])
        st.info("â¬†ï¸ ìœ„ ë‚´ìš©ì„ ìº¡ì³í•´ì„œ ë³´ë‚´ë©´ ë°”ë¡œ ë§ì¶°ë“œë¦´ ìˆ˜ ìˆì–´ìš”. (íŒŒì‹±ì€ ì—¬ê¸°ì„œ ì¤‘ë‹¨)")
        st.stop()

    # ë‹¨ì¼ ì»¬ëŸ¼ CSV â†’ ë¶„ë¦¬ì ìë™ ê°ì§€
    if int(raw.shape[1]) == 1:
        try:
            sample_text = "\n".join(raw.iloc[:min(5, len(raw)), 0].astype(str).tolist())
            found_sep = None
            for s in (",", "\t", ";", "|"):
                if sample_text.find(s) != -1:  # ìŠ¤ì¹¼ë¼ ë¬¸ìì—´ ê²€ì‚¬
                    found_sep = s
                    break
            if found_sep is not None:
                col0 = raw.iloc[:, 0].astype(str)
                raw = col0.str.split(found_sep, expand=True)
        except Exception:
            pass

    # í—¤ë” ë‘ ì¤„ì—ì„œ ì—°ë„/ì§€í‘œ ì¶”ì¶œ
    row0 = raw.iloc[0]
    row1 = raw.iloc[1]
    if isinstance(row0, pd.DataFrame): row0 = row0.squeeze(axis=0)
    if isinstance(row1, pd.DataFrame): row1 = row1.squeeze(axis=0)

    years = row0.astype(str).str.strip().values
    names = row1.astype(str).str.strip().values

    df = raw.iloc[2:].copy()
    df.columns = pd.MultiIndex.from_arrays([names, years], names=["Indicator", "Year"])

    # ìˆ«ì í´ë¦¬ë‹ (Series ì „ìš© .str)
    def clean_series(s: pd.Series) -> pd.Series:
        s = s.astype(str)
        s = s.str.replace(",", "", regex=False)
        s = s.str.replace(r"[^0-9eE+\-\.]", "", regex=True)
        return pd.to_numeric(s, errors="coerce")

    for j in range(df.shape[1]):
        df.iloc[:, j] = clean_series(df.iloc[:, j])

    # Yearë¥¼ ê°€ëŠ¥í•œ intë¡œ ìºìŠ¤íŒ…
    try:
        new_cols = []
        for ind, yr in df.columns:
            ystr = str(yr)
            if ystr.replace(".", "", 1).isdigit():
                yv = int(float(ystr))
            else:
                yv = yr
            new_cols.append((ind, yv))
        df.columns = pd.MultiIndex.from_tuples(new_cols, names=["Indicator", "Year"])
    except Exception:
        pass

    # (Indicator,Year) ì¤‘ë³µ â†’ í‰ê· 
    if bool(df.columns.duplicated(keep=False).any()):
        df = df.T.groupby(level=["Indicator", "Year"]).mean(numeric_only=True).T
        df.index = pd.RangeIndex(len(df))

    return df


def s_at_v2(df_mi: pd.DataFrame, name: str, year) -> pd.Series:
    """(Indicator=name, Year=year) Series ì•ˆì „ ë°˜í™˜(ì—†ìœ¼ë©´ NaN Series)."""
    lvl0 = df_mi.columns.get_level_values(0)
    if name in set(lvl0):
        sub = df_mi.loc[:, name]
        cols = list(sub.columns) if hasattr(sub, "columns") else []
        if year in cols:
            return df_mi.loc[:, (name, year)]
    return pd.Series([np.nan] * len(df_mi), index=df_mi.index)


# =========================
# BUILD REGRESSION DATA
# =========================
def build_pair_dataset(df_mi: pd.DataFrame, x_year: int, y_year: int) -> pd.DataFrame:
    """GERD(x_year) â†’ GDP(y_year), ë‚˜ë¨¸ì§€ ëª¨ë‘ y_year ê¸°ì¤€ìœ¼ë¡œ êµ¬ì„± + ë¡œê·¸ ë³€í™˜."""
    out = pd.DataFrame(index=df_mi.index)

    out["GERD"] = s_at_v2(df_mi, GERD_NAME, x_year)
    out["GDP"]  = s_at_v2(df_mi, GDP_NAME,  y_year)

    for v in CONFOUNDER_NAMES + MEDIATOR_NAMES + MODERATOR_NAMES:
        out[v] = s_at_v2(df_mi, v, y_year)

    # ë¡œê·¸ ë³€í™˜: 0 â†’ NaN
    out["ln_X"] = np.log(out["GERD"].replace({0: np.nan}))
    out["ln_Y"] = np.log(out["GDP"].replace({0: np.nan}))
    out = out.dropna(subset=["ln_X", "ln_Y"]).reset_index(drop=True)
    return out


def run_models(df_reg: pd.DataFrame):
    """Model 1~4 ì‹¤í–‰ + ë¹„êµí‘œ(Î²_lnX, p_lnX, Adj.RÂ²)."""
    confs = [c for c in CONFOUNDER_NAMES if c in df_reg.columns]
    meds  = [m for m in MEDIATOR_NAMES  if m in df_reg.columns]
    mods  = [m for m in MODERATOR_NAMES if m in df_reg.columns]

    # M1
    m1 = smf.ols("ln_Y ~ ln_X", data=df_reg).fit()
    # M2
    rhs2 = "ln_X" + ((" + " + " + ".join([f'Q(\"{c}\")' for c in confs])) if len(confs) > 0 else "")
    m2 = smf.ols(f"ln_Y ~ {rhs2}", data=df_reg).fit()
    # M3
    rhs3 = rhs2 + ((" + " + " + ".join([f'Q(\"{m}\")' for m in meds])) if len(meds) > 0 else "")
    m3 = smf.ols(f"ln_Y ~ {rhs3}", data=df_reg).fit()
    # M4 (interaction)
    inter = " + ".join([f'ln_X * Q(\"{mo}\")' for mo in mods]) if len(mods) > 0 else ""
    rhs4 = rhs3 if len(inter) == 0 else f"{rhs3} + {inter}"
    m4 = smf.ols(f"ln_Y ~ {rhs4}", data=df_reg).fit()

    def pick(mod, key="ln_X"):
        return mod.params.get(key, np.nan), mod.pvalues.get(key, np.nan), mod.rsquared_adj

    rows = []
    for label, mod in [("M1: lnY~lnX", m1), ("M2:+conf", m2), ("M3:+med", m3), ("M4:+mods", m4)]:
        beta, pval, adjr2 = pick(mod, "ln_X")
        rows.append([label, beta, pval, adjr2])

    summary = pd.DataFrame(rows, columns=["Model", "Î²(ln_X)", "p(ln_X)", "Adj.RÂ²"]).round(4)
    return {"M1": m1, "M2": m2, "M3": m3, "M4": m4}, summary


# =========================
# UI
# =========================
st.title("ğŸ“ˆ GERD(2020) â†’ GDP(2023) â€“ Models 1~4 with Viz & Debug")

with st.sidebar:
    st.markdown("### âš™ï¸ Options")
    debug_mode = st.checkbox("Show raw header debug (row0/row1) and stop", value=False)
    st.caption("ë””ë²„ê·¸ë¥¼ ì¼œë©´ ì›ì‹œ í—¤ë”ë¥¼ ì¶œë ¥í•˜ê³  ì•±ì„ ë©ˆì¶¥ë‹ˆë‹¤.")

# 1) LOAD
try:
    df_mi = read_as_multiindex_v2(DATA_FILE, debug=debug_mode)
except Exception as e:
    st.error(f"Error loading data: {e}")
    st.stop()

st.success("âœ… Dataset loaded & cleaned (Row0=Year / Row1=Indicator).")

# ì§€í‘œëª… ì˜¤íƒˆì ì•ˆë‚´: ì‹¤ì œ CSVì— ìˆëŠ” ì§€í‘œëª… í›„ë³´ë¥¼ ë³´ì—¬ì£¼ê³  ê·¼ì‚¬ ì¼ì¹˜ ì œì•ˆ
available_names = sorted(set(df_mi.columns.get_level_values(0)))
needed = [GDP_NAME, GERD_NAME] + MEDIATOR_NAMES + CONFOUNDER_NAMES + MODERATOR_NAMES
missing = [n for n in needed if n not in available_names]
if len(missing) > 0:
    st.warning("ë‹¤ìŒ ì§€í‘œëª…ì´ CSVì—ì„œ ë°œê²¬ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤(ì² ì/ê³µë°±/ê¸°í˜¸ í™•ì¸):")
    for m in missing:
        sugg = get_close_matches(m, available_names, n=3, cutoff=0.6)
        st.write(f"- `{m}`  â†’  í›„ë³´: {sugg}")
    st.info("âš ï¸ ì§€í‘œëª…ì´ ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ íšŒê·€ ë°ì´í„°ì…‹ì´ ë¹„ê²Œ ë©ë‹ˆë‹¤.")

# 2) ë¶„í¬/ìƒê´€
st.header("ğŸ“Š Distributions & Correlations")
flat = df_mi.copy()
flat.columns = [f"{a} [{b}]" for a, b in flat.columns]
num_only = flat.select_dtypes(include=np.number)
if bool(num_only.empty) is False:
    st.write(num_only.describe().T)
    try:
        fig_corr, ax_corr = plt.subplots(figsize=(12, 7))
        sns.heatmap(num_only.corr(), cmap="coolwarm", center=0, ax=ax_corr)
        ax_corr.set_title("Correlation Heatmap (All numeric columns)")
        st.pyplot(fig_corr)
    except Exception:
        st.info("Correlation heatmap skipped.")
else:
    st.info("No numeric columns available after parsing.")

# 3) ê³ ì • í˜ì–´: GERD(2020) â†’ GDP(2023) (ë‚˜ë¨¸ì§€ ì „ë¶€ 2023)
st.markdown("---")
st.header(f"ğŸ§® Pair: GERD({X_YEAR}) â†’ GDP({Y_YEAR})  (All other vars at {Y_YEAR})")

df_reg = build_pair_dataset(df_mi, X_YEAR, Y_YEAR)
if df_reg.empty:
    st.error("íšŒê·€ì— ì‚¬ìš©í•  í‘œë³¸ì´ ì—†ìŠµë‹ˆë‹¤. (ln_X/ln_Y after cleaning). "
             "CSV ì§€í‘œëª…/ì—°ë„ í—¤ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”. (ì‚¬ì´ë“œë°”ì˜ Debugë¡œ ì›ë³¸ í—¤ë” í™•ì¸ ê°€ëŠ¥)")
    st.stop()

st.subheader("ğŸ“‹ Regression dataset (preview)")
st.dataframe(df_reg.head())

# 4) ì‚°ì ë„(lnX-lnY)
st.subheader("ğŸ“‰ ln(GERD) vs ln(GDP)")
fig_sc, ax_sc = plt.subplots(figsize=(7, 5))
sns.regplot(x="ln_X", y="ln_Y", data=df_reg, scatter_kws={"alpha": 0.6}, ax=ax_sc)
ax_sc.set_xlabel(f"ln GERD ({X_YEAR})")
ax_sc.set_ylabel(f"ln GDP ({Y_YEAR})")
st.pyplot(fig_sc)

# 5) ëª¨ë¸ 1~4
models, table = run_models(df_reg)
st.subheader("ğŸ“˜ Model Comparison (Î²_lnX, p, Adj.RÂ²)")
st.dataframe(table)

fig_r2, ax_r2 = plt.subplots(figsize=(6, 4))
sns.barplot(x="Model", y="Adj.RÂ²", data=table, ax=ax_r2)
ymax = float(table["Adj.RÂ²"].max()) if len(table) else 1.0
ax_r2.set_ylim(0, max(0.1, ymax) * 1.1)
ax_r2.set_title("Adjusted RÂ² across models")
st.pyplot(fig_r2)

with st.expander("Full regression summaries"):
    for k, m in models.items():
        st.markdown(f"**{k}**")
        st.text(m.summary())

# 6) í•´ì„
st.markdown("""
### ğŸ§© Interpretation (2020â†’2023)
- **Model 1**: lnGERD(2020) â†’ lnGDP(2023) ê¸°ë³¸ íƒ„ë ¥ì„±.
- **Model 2**: GDP per Capita, Labor Force(2023) í†µì œë¡œ **í˜¼ë€íš¨ê³¼** ì ê²€(lnGERD ê³„ìˆ˜ ë³€í™”).
- **Model 3**: íŠ¹í—ˆÂ·ì—°êµ¬ì¸ë ¥Â·í•˜ì´í…Œí¬ìˆ˜ì¶œÂ·ê¸°ì—…R&Dì¸ë ¥(2023) ì¶”ê°€ â†’ lnGERD ê³„ìˆ˜ ê°ì†Œ/ìœ ì˜ì„± ë³€í™” ì‹œ **ë§¤ê°œíš¨ê³¼** ì‹œì‚¬.
- **Model 4**: Government/Business-financed BERD(2023) ìƒí˜¸ì‘ìš©ì´ ìœ ì˜(p<0.05)í•˜ë©´ **ì¡°ì ˆíš¨ê³¼** ì¡´ì¬.
""")