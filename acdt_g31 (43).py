# -*- coding: utf-8 -*-
"""acdt_g31

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F5fm0D95_3CLMpKv3LVVCJCWz4Vwmcv_
"""

import re
import numpy as np
import pandas as pd
import streamlit as st
import statsmodels.formula.api as smf
import matplotlib.pyplot as plt
import seaborn as sns

st.set_page_config(page_title="GERD(2020) â†’ GDP(2023) â€“ Full Regressions (w/ Debug)", layout="wide")

CSV_NAME = "ACDT_final_dataset.csv"

# -------------------- ìœ í‹¸ --------------------
def coerce_numeric_series_like(df_like: pd.DataFrame) -> pd.DataFrame:
    """
    ë©€í‹°ì¸ë±ìŠ¤ ì „ì²´(ìˆ˜ì¹˜ì˜ì—­)ì— ëŒ€í•´ ë²¡í„°í™”ë¡œ ìˆ«ìë§Œ ë‚¨ê¸°ê³  float ë³€í™˜.
    * ê´„í˜¸(...) ë‚´ë¶€ í…ìŠ¤íŠ¸ ì œê±°
    * ìˆ«ì/./- ì´ì™¸ ì œê±°
    * ë¹ˆ ë¬¸ìì—´ -> NaN
    """
    # ë¬¸ìì—´í™”
    tmp = df_like.astype(str)

    # ê´„í˜¸ ì•ˆ í…ìŠ¤íŠ¸ ì œê±°
    tmp = tmp.replace(r"\([^)]*\)", "", regex=True)
    # ìˆ«ì/.- ì´ì™¸ ì „ë¶€ ì œê±°
    tmp = tmp.replace(r"[^0-9.\-]", "", regex=True)
    # ë¹ˆë¬¸ì -> NaN
    tmp = tmp.replace(r"^\s*$", np.nan, regex=True)

    # to_numeric (ë²¡í„°í™”)
    # DataFrame ì „ì²´ì— apply(pd.to_numeric)ëŠ” ëŠë ¤ì„œ, stack->to_numeric->unstackì´ ë” ì•ˆì •ì ì„
    stacked = tmp.stack(dropna=False)
    stacked = pd.to_numeric(stacked, errors="coerce")
    restored = stacked.unstack()
    return restored

def anycol(wide: pd.DataFrame, patterns):
    """ì •ê·œì‹ ë¦¬ìŠ¤íŠ¸ ì¤‘ ì²« ë§¤ì¹­ ì—´ ë°˜í™˜(None ê°€ëŠ¥)."""
    for p in patterns:
        r = re.compile(p, re.I)
        hit = [c for c in wide.columns if r.search(str(c))]
        if hit:
            return hit[0]
    return None

# -------------------- 1) ë¡œë“œ & ì •ë¦¬ --------------------
@st.cache_data(show_spinner=True)
def load_and_tidy(csv_name=CSV_NAME):
    raw = pd.read_csv(csv_name, header=None)
    st.write("ğŸ” DEBUG: raw shape", raw.shape)

    # ì²« ë‘ í–‰ì„ í—¤ë”ë¡œ ì‚¬ìš©
    raw.iloc[0, 0] = "Country"
    raw.iloc[1, 0] = "Indicator"

    years_row = raw.iloc[0].fillna("").astype(str).tolist()
    inds_row  = raw.iloc[1].fillna("").astype(str).tolist()

    # MultiIndex ì»¬ëŸ¼ ìƒì„±
    cols = []
    for j in range(raw.shape[1]):
        if j == 0:
            cols.append(("Country", ""))
        else:
            cols.append((inds_row[j].strip(), years_row[j].strip()))
    mi_cols = pd.MultiIndex.from_tuples(cols, names=["Indicator", "Year"])
    raw.columns = mi_cols

    # ë°ì´í„° ë¶€ë¶„ë§Œ
    df = raw.iloc[2:].copy()
    df = df.rename(columns={("Country", ""): "Country"})
    df["Country"] = df["Country"].astype(str).str.strip()

    # ì „ì²´ ì—´ í”„ë¦°íŠ¸(ì•ë¶€ë¶„)
    st.write("ğŸ” DEBUG: columns (head 25)", list(df.columns)[:25])

    # ìˆ˜ì¹˜ ì˜ì—­: Country ì œì™¸ ë©€í‹°ì¸ë±ìŠ¤ ì „ì²´
    mask = [c for c in df.columns if not (isinstance(c, str) and c == "Country")]
    numeric_block = df.loc[:, mask]

    # (ì¤‘ìš”) ë©€í‹°ì¸ë±ìŠ¤ ì „ì²´ ìŠ¬ë¼ì´ìŠ¤ì— ë²¡í„°í™” ì „ì²˜ë¦¬ â†’ lexsort warning ì œê±°
    numeric_clean = coerce_numeric_series_like(numeric_block)

    # ê²°í•©
    df_clean = pd.concat([df[["Country"]], numeric_clean], axis=1)

    # Long í˜•íƒœ
    long = (
        df_clean
        .set_index("Country")
        .stack(level=["Indicator", "Year"])
        .reset_index()
        .rename(columns={0: "value"})
    )

    # Wide: "Indicator | Year"
    long["colkey"] = long["Indicator"].str.strip() + " | " + long["Year"].str.strip()
    wide = long.pivot_table(index="Country", columns="colkey", values="value", aggfunc="first")
    wide.columns = wide.columns.astype(str)

    # ë””ë²„ê¹…: ê²°ì¸¡ í†µê³„
    st.write("ğŸ” DEBUG: long shape", long.shape, "wide shape", wide.shape)
    st.write("ğŸ” DEBUG: sample long", long.head(8))
    st.write("ğŸ” DEBUG: non-null counts (wide) â€“ top 20",
             wide.notna().sum().sort_values(ascending=False).head(20))

    return long, wide

# -------------------- 2) ì»¬ëŸ¼ ë§¤í•‘ --------------------
def extract_columns(wide, gerd_year="2020", gdp_year="2023"):
    # í›„ë³´ íŒ¨í„´
    gerd_candidates = [
        r"Gross Domestic Expenditure on R&D.*current.*USD",
        r"GERD.*current.*USD",
        r"R&D Expenditure Ratio.*% of GDP",
        r"R&D Expenditure Ratio"
    ]
    gdp_real_pat     = r"Real GDP \(billion USD.*Chain-weighted.*2020 base year\)"
    patents_res_pat  = r"Resident Patent Applications"
    patents_non_pat  = r"Non-Resident Patent Applications"
    rd_researchers   = r"Number of R&D Researcher"
    hightech_share   = r"High-Tech Export Share.*% of Manufacturing Exports"
    gdp_capita_pat   = r"GDP per Capita \(USD per person, PPP-based, Nominal\)"

    # 2023 ê³ ì • ê¶Œì¥, ì—†ìœ¼ë©´ None â†’ ëª¨ë¸ì—ì„œ ìë™ ê±´ë„ˆëœ€
    def find_yeared(regex, year):
        pat = re.compile(regex, re.I)
        hits = [c for c in wide.columns if pat.search(str(c)) and c.endswith(f"| {year}")]
        return hits[0] if hits else None

    # GERD(ì—°ë„)
    gerd_col = None
    for pat in gerd_candidates:
        hit = find_yeared(pat, gerd_year)
        if hit:
            gerd_col = hit
            break

    gdp_col       = find_yeared(gdp_real_pat, gdp_year)
    res_pat_col   = find_yeared(patents_res_pat, "2023")
    non_pat_col   = find_yeared(patents_non_pat, "2023")
    rd_col        = find_yeared(rd_researchers, "2023")
    hte_col       = find_yeared(hightech_share, "2023")
    gdp_pc_col    = find_yeared(gdp_capita_pat, "2023")

    # BERD ì¡°ì ˆìëŠ” ë°ì´í„°ì…‹ì— ì—†ì„ ê°€ëŠ¥ì„± ë†’ìœ¼ë¯€ë¡œ optional
    berd_gov_col  = anycol(wide, [r"Government-financed BERD \(%\) \| 2023"])
    berd_biz_col  = anycol(wide, [r"Business-financed BERD \(%\) \| 2023"])

    found = {
        "GERD": gerd_col,
        "Real_GDP": gdp_col,
        "Resident_Patents": res_pat_col,
        "NonResident_Patents": non_pat_col,
        "R&D_Researchers_per_million": rd_col,
        "HighTech_Export_Share": hte_col,
        "GDP_per_Capita": gdp_pc_col,
        "GovFinanced_BERD_pct": berd_gov_col,
        "BizFinanced_BERD_pct": berd_biz_col,
    }
    return found

# -------------------- 3) ë¶„ì„ DF êµ¬ì„± --------------------
def build_model_df(wide, mapping):
    missing = [k for k, v in mapping.items() if k in ("GERD", "Real_GDP") and (v is None)]
    if missing:
        return None, f"Required columns missing: {missing}"

    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì—´ë§Œ ì„ íƒ
    use = {k: v for k, v in mapping.items() if v is not None}
    dfm = wide[list(use.values())].copy()
    dfm.columns = list(use.keys())

    # ë¡œê·¸ë³€í™˜(ì–‘ìˆ˜ë§Œ)
    for c in ("GERD", "Real_GDP", "GDP_per_Capita"):
        if c in dfm.columns:
            dfm[f"ln_{c}"] = np.where(dfm[c] > 0, np.log(dfm[c]), np.nan)

    # ì½”ì–´ ê²°ì¸¡ ì œê±°
    core = [c for c in ("ln_GERD", "ln_Real_GDP") if c in dfm.columns]
    dfm = dfm.dropna(subset=core)

    # ë””ë²„ê¹…
    st.write("ğŸ” DEBUG: model df shape", dfm.shape)
    st.write("ğŸ” DEBUG: NA counts", dfm.isna().sum().to_dict())

    # index=Country ë¡œ ë…¸ì¶œë˜ë„ë¡ reset
    return dfm.reset_index(), None

# -------------------- 4) íšŒê·€ ì í•© --------------------
def fit_models(dfm):
    res = {}

    # Model 1
    m1 = smf.ols("ln_Real_GDP ~ ln_GERD", data=dfm).fit()
    res["Model 1"] = m1

    # Model 2 (confounder)
    if "GDP_per_Capita" in dfm.columns:
        m2 = smf.ols("ln_Real_GDP ~ ln_GERD + GDP_per_Capita", data=dfm).fit()
    else:
        m2 = m1
    res["Model 2"] = m2

    # Model 3 (mediators)
    meds = [c for c in ["Resident_Patents","NonResident_Patents","R&D_Researchers_per_million","HighTech_Export_Share"] if c in dfm.columns]
    if meds:
        m3 = smf.ols("ln_Real_GDP ~ ln_GERD + " + " + ".join(meds), data=dfm).fit()
    else:
        m3 = m2
    res["Model 3"] = m3

    # Model 4 (moderators)
    mods = [c for c in ["GovFinanced_BERD_pct","BizFinanced_BERD_pct"] if c in dfm.columns]
    if mods:
        inter = " + ".join([f"ln_GERD:{m}" for m in mods])
        rhs = "ln_GERD " + ("+ " + " + ".join(meds) if meds else "") + (" + " + " + ".join(mods) if mods else "") + " + " + inter
        m4 = smf.ols(f"ln_Real_GDP ~ {rhs}", data=dfm).fit()
    else:
        m4 = m3
    res["Model 4"] = m4

    return res

# -------------------- 5) ì•± --------------------
st.title("ğŸ“ˆ GERD(2020) â†’ GDP(2023) â€“ Full Regressions (Model 1â€“4)")

with st.spinner("Loading & cleaning data..."):
    try:
        long, wide = load_and_tidy(CSV_NAME)
    except Exception as e:
        st.error(f"âŒ Error loading data: {e}")
        st.stop()

st.success(f"Loaded: long={long.shape}, wide={wide.shape}")

colA, colB = st.columns(2)
with colA: gerd_year = st.selectbox("GERD year", ["2020","2021","2022","2023"], index=0)
with colB: gdp_year  = st.selectbox("Real GDP year", ["2023","2022","2021"], index=0)

mapping = extract_columns(wide, gerd_year=gerd_year, gdp_year=gdp_year)
st.subheader("ğŸ” Matched columns")
st.json(mapping)

dfm, err = build_model_df(wide, mapping)
if err:
    st.error(f"âŒ {err}")
    st.stop()

st.subheader("ğŸ“‹ Analysis Data (head)")
st.dataframe(dfm.head(10), use_container_width=True)

# ë¶„í¬ ì‹œê°í™”
st.subheader("ğŸ“Š Variable Distributions")
num_cols = [c for c in dfm.columns if dfm[c].dtype != "O"]
sel = st.multiselect("Select variables", num_cols, default=[c for c in ["ln_GERD","ln_Real_GDP","GDP_per_Capita"] if c in num_cols])
if sel:
    fig, axes = plt.subplots(nrows=len(sel), ncols=1, figsize=(7, 2.6*len(sel)))
    if len(sel) == 1:
        axes = [axes]
    for ax, c in zip(axes, sel):
        sns.histplot(dfm[c].dropna(), kde=True, ax=ax)
        ax.set_title(c)
    st.pyplot(fig)

# íšŒê·€
results = fit_models(dfm)

st.subheader("ğŸ“˜ Model Comparison")
rows = []
for name, m in results.items():
    rows.append([name, m.params.get("ln_GERD", np.nan), m.pvalues.get("ln_GERD", np.nan), m.rsquared_adj])
comp = pd.DataFrame(rows, columns=["Model","Î²(ln_GERD)","p-value","Adj.RÂ²"])
st.dataframe(comp, use_container_width=True)

fig2, ax2 = plt.subplots(figsize=(6,3))
sns.barplot(data=comp, x="Model", y="Adj.RÂ²", ax=ax2)
ax2.set_ylim(0, 1)
st.pyplot(fig2)

with st.expander("ğŸ“„ Full regression summaries"):
    for name, m in results.items():
        st.markdown(f"### {name}")
        st.text(m.summary())