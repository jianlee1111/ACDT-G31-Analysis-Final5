# -*- coding: utf-8 -*-
"""acdt_g31

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F5fm0D95_3CLMpKv3LVVCJCWz4Vwmcv_
"""

# ================================================================
# üìä ACDT Group 31 Final Streamlit App ‚Äì Clean & Regression Version
# ================================================================
# Includes:
# - Robust numeric cleaning (removes commas, units, text)
# - Float-safe preprocessing (fixes 'isalpha' error)
# - Log-transform for GDP & GERD
# - Variable distribution + correlation + regression models
# ================================================================

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.formula.api as smf

st.set_page_config(page_title="ACDT Group 31 Full Analysis", layout="wide")

# ================================================================
# 1Ô∏è‚É£ Data Loading & Preprocessing
# ================================================================
@st.cache_data
def load_data():
    try:
        # Load CSV with safe encoding
        df = pd.read_csv("ACDT_final_dataset.csv", encoding="utf-8-sig")

        # Clean potential invisible characters from column names
        df.columns = [col.strip().replace('\u202c', '').replace('\u200b', '') for col in df.columns]

        # Handle case where top rows may be metadata
        first_value = str(df.iloc[0, 0])
        if not first_value.isalpha():
            df = df.iloc[2:].copy()

        # ‚úÖ Numeric cleaning: remove commas, text, symbols, keep digits/signs/decimal/exponent
        for col in df.columns[1:]:
            df[col] = (
                df[col]
                .astype(str)
                .str.replace(',', '', regex=False)             # remove commas
                .str.replace('[^0-9eE+.-]', '', regex=True)    # remove all non-numeric characters
            )
            df[col] = pd.to_numeric(df[col], errors='coerce')

        # Drop empty or invalid rows
        df.dropna(inplace=True)

        # Rename for regression consistency
        df.rename(columns={
            'Real GDP (billion USD, PPP-based, Chain-weighted, 2020 base year)': 'Real_GDP',
            'Gross Domestic Expenditure on R&D (GERD) (current PPP USD)': 'GERD'
        }, inplace=True)

        # ‚úÖ Log transform (safe for zeros)
        if 'Real_GDP' in df.columns and 'GERD' in df.columns:
            df['ln_GDP'] = np.log(df['Real_GDP'].replace(0, np.nan))
            df['ln_GERD'] = np.log(df['GERD'].replace(0, np.nan))
        else:
            st.error("‚ö†Ô∏è Missing 'Real_GDP' or 'GERD' columns. Check dataset headers.")
            st.write(df.columns.tolist())
            return pd.DataFrame()

        return df

    except Exception as e:
        st.error(f"‚ùå Error loading data: {e}")
        return pd.DataFrame()

# ================================================================
# 2Ô∏è‚É£ Load Data
# ================================================================
st.title("üìà GERD and GDP Regression Dashboard ‚Äì ACDT Group 31")
df = load_data()

if df.empty:
    st.error("‚ö†Ô∏è Data could not be loaded. Please check file name or encoding.")
    st.stop()
else:
    st.success("‚úÖ Data successfully loaded and cleaned!")
    st.dataframe(df.head())

# ================================================================
# 3Ô∏è‚É£ Variable Distribution Visualization
# ================================================================
st.header("üìä Variable Distribution")

num_cols = df.select_dtypes(include=np.number).columns.tolist()
if num_cols:
    var = st.selectbox("Select variable to visualize:", num_cols)
    fig, ax = plt.subplots(1, 2, figsize=(12, 4))
    sns.histplot(df[var], kde=True, ax=ax[0], color="skyblue")
    ax[0].set_title(f"Distribution of {var}")
    sns.boxplot(x=df[var], ax=ax[1], color="salmon")
    ax[1].set_title(f"Boxplot of {var}")
    st.pyplot(fig)

# ================================================================
# 4Ô∏è‚É£ Correlation Heatmap
# ================================================================
st.header("üìà Correlation Matrix")
corr = df.select_dtypes(include=np.number).corr()
fig_corr, ax_corr = plt.subplots(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f", ax=ax_corr)
st.pyplot(fig_corr)

# ================================================================
# 5Ô∏è‚É£ Regression Models (Simple ‚Üí Mediator/Moderator)
# ================================================================
st.header("üßÆ Regression Models (Model 1‚Äì4)")

confounders = ['GDP per Capita', 'Labor Force Size']
mediators = [
    'Resident Patent Applications',
    'Non-Resident Patent Applications',
    'R&D Researchers per Million People',
    'High-tech Export Share (% of Manufactured Exports)',
    'Business R&D Personnel (FTE)'
]
moderators = [
    'Government-financed BERD (%)',
    'Business-financed BERD (%)'
]

models = {}

try:
    # Model 1: Simple regression
    models['Model 1'] = smf.ols('ln_GDP ~ ln_GERD', data=df).fit()

    # Model 2: Confounders
    valid_conf = [c for c in confounders if c in df.columns]
    if valid_conf:
        models['Model 2'] = smf.ols(f"ln_GDP ~ ln_GERD + {' + '.join([f'Q(\"{c}\")' for c in valid_conf])}", data=df).fit()
    else:
        models['Model 2'] = models['Model 1']

    # Model 3: Mediators
    valid_med = [m for m in mediators if m in df.columns]
    if valid_med:
        models['Model 3'] = smf.ols(f"ln_GDP ~ ln_GERD + {' + '.join([f'Q(\"{m}\")' for m in valid_med])}", data=df).fit()
    else:
        models['Model 3'] = models['Model 2']

    # Model 4: Moderators (interaction)
    valid_mod = [mo for mo in moderators if mo in df.columns]
    if valid_mod:
        interaction = ' + '.join([f'ln_GERD * Q(\"{mo}\")' for mo in valid_mod])
        models['Model 4'] = smf.ols(f"ln_GDP ~ {interaction} + {' + '.join([f'Q(\"{m}\")' for m in valid_med])}", data=df).fit()
    else:
        models['Model 4'] = models['Model 3']

    # ================================================================
    # 6Ô∏è‚É£ Model Comparison Summary
    # ================================================================
    summary_data = []
    for name, m in models.items():
        coef = m.params.get('ln_GERD', np.nan)
        pval = m.pvalues.get('ln_GERD', np.nan)
        adjr2 = m.rsquared_adj
        summary_data.append([name, round(coef, 4), round(pval, 4), round(adjr2, 4)])

    summary_df = pd.DataFrame(summary_data, columns=['Model', 'Œ≤(ln_GERD)', 'p-value', 'Adj. R¬≤'])
    st.subheader("üìò Model Comparison Summary")
    st.dataframe(summary_df)

    fig_r2, ax_r2 = plt.subplots()
    sns.barplot(x='Model', y='Adj. R¬≤', data=summary_df, palette="Blues_d", ax=ax_r2)
    ax_r2.set_title("Adjusted R¬≤ Across Models")
    st.pyplot(fig_r2)

    # ================================================================
    # 7Ô∏è‚É£ Interpretive Summary
    # ================================================================
    st.header("üß© Interpretive Summary")
    top_model = summary_df.loc[summary_df['Adj. R¬≤'].idxmax(), 'Model']
    st.markdown(f"**Best-fitting model:** {top_model}")

    st.markdown("""
    - **Model 1:** Direct elasticity of GDP w.r.t GERD.
    - **Model 2:** Adds confounders (GDP per capita, labor force).
    - **Model 3:** Adds mediators (innovation activity, human capital).
    - **Model 4:** Includes moderators (public/private R&D shares).

    **Interpretation:**
    GERD positively correlates with GDP in all models.
    Mediators partially explain indirect innovation effects,
    while moderators indicate how policy allocation modifies this relationship.
    """)

    with st.expander("üìÑ Full Regression Summaries"):
        for name, model in models.items():
            st.markdown(f"### {name}")
            st.text(model.summary())

except Exception as e:
    st.error(f"‚ùå Regression error: {e}")