# -*- coding: utf-8 -*-
"""acdt_g31

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F5fm0D95_3CLMpKv3LVVCJCWz4Vwmcv_
"""

# -*- coding: utf-8 -*-
# Streamlit App: ACDT G31 – GERD(2020) → GDP(2023)
# Fully corrected version (2025-10-17)

import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf
import warnings

warnings.filterwarnings("ignore")

# --- Streamlit page setup ---
st.set_page_config(page_title="ACDT G31 – GERD(2020) → GDP(2023)", layout="wide")
st.title("📈 GERD(2020) → GDP(2023) – Full Regression Models (1–4)")

# --- Data file ---
DATA_FILE = "ACDT_final_dataset.csv"

# --- Label definitions ---
GDP_NAME = "Real GDP (billion USD, PPP-based, Chain-weighted, 2020 base year)"
GERD_NAME = "Gross Domestic Expenditure on R&D (GERD) (current PPP USD)"
MEDIATOR_NAMES = [
    "Resident Patent Applications",
    "Non-Resident Patent Applications",
    "R&D Researchers per Million People",
    "High-tech Export Share (% of Manufactured Exports)",
    "Business R&D Personnel (FTE)"
]
CONFOUNDER_NAMES = ["GDP per Capita", "Labor Force Size"]
MODERATOR_NAMES = ["Government-financed BERD (%)", "Business-financed BERD (%)"]

X_YEAR = 2020   # GERD 기준 연도
Y_YEAR = 2023   # GDP 및 기타 변수 기준 연도

# --- Safe data loading with caching ---
@st.cache_data
def read_as_multiindex(path: str) -> pd.DataFrame:
    """Read CSV and construct MultiIndex DataFrame: Row0=Year, Row1=Indicator."""
    try:
        df = pd.read_csv(path, header=None, encoding='utf-8-sig')
    except Exception:
        df = pd.read_csv(path, header=None, encoding='cp949')

    if df.shape[1] == 1:  # Single-column CSV (text)
        text = "\n".join(df.iloc[:5, 0].astype(str))
        sep = "," if "," in text else ";" if ";" in text else "\t"
        df = df.iloc[:, 0].astype(str).str.split(sep, expand=True)

    years = df.iloc[0].astype(str).str.strip().values
    names = df.iloc[1].astype(str).str.strip().values
    data = df.iloc[2:].copy()
    data.columns = pd.MultiIndex.from_arrays([names, years], names=["Indicator", "Year"])

    def clean_series(s: pd.Series) -> pd.Series:
        s = s.astype(str)
        s = s.str.replace(",", "", regex=False)
        s = s.str.replace(r"[^0-9eE+\-\.]", "", regex=True)
        return pd.to_numeric(s, errors="coerce")

    for c in data.columns:
        data[c] = clean_series(data[c])

    if data.columns.duplicated().any():
        data = data.T.groupby(level=[0, 1]).mean(numeric_only=True).T

    return data.reset_index(drop=True)

# --- Safe Series Access ---
def s_at(df_mi: pd.DataFrame, name: str, year) -> pd.Series:
    if name not in df_mi.columns.get_level_values(0):
        return pd.Series([np.nan] * len(df_mi))
    sub = df_mi.loc[:, name]
    if year not in sub.columns:
        return pd.Series([np.nan] * len(df_mi))
    return df_mi.loc[:, (name, year)]

# --- Dataset building ---
def build_pair_dataset(df_mi: pd.DataFrame, x_year: int, y_year: int) -> pd.DataFrame:
    out = pd.DataFrame(index=df_mi.index)
    out["GERD"] = s_at(df_mi, GERD_NAME, x_year)
    out["GDP"] = s_at(df_mi, GDP_NAME, y_year)
    for v in CONFOUNDER_NAMES + MEDIATOR_NAMES + MODERATOR_NAMES:
        out[v] = s_at(df_mi, v, y_year)
    out["ln_X"] = np.log(out["GERD"].replace({0: np.nan}))
    out["ln_Y"] = np.log(out["GDP"].replace({0: np.nan}))
    return out.dropna(subset=["ln_X", "ln_Y"]).reset_index(drop=True)

# --- Regression models ---
def run_models(df_reg: pd.DataFrame):
    confs = [c for c in CONFOUNDER_NAMES if c in df_reg.columns]
    meds = [m for m in MEDIATOR_NAMES if m in df_reg.columns]
    mods = [m for m in MODERATOR_NAMES if m in df_reg.columns]

    results = []
    models = {}

    m1 = smf.ols("ln_Y ~ ln_X", data=df_reg).fit()
    models["M1"] = m1
    rhs2 = "ln_X" + ((" + " + " + ".join([f'Q(\"{c}\")' for c in confs])) if confs else "")
    m2 = smf.ols(f"ln_Y ~ {rhs2}", data=df_reg).fit()
    models["M2"] = m2
    rhs3 = rhs2 + ((" + " + " + ".join([f'Q(\"{m}\")' for m in meds])) if meds else "")
    m3 = smf.ols(f"ln_Y ~ {rhs3}", data=df_reg).fit()
    models["M3"] = m3
    inter = " + ".join([f'ln_X * Q(\"{mo}\")' for mo in mods]) if mods else ""
    rhs4 = rhs3 + (" + " + inter if inter else "")
    m4 = smf.ols(f"ln_Y ~ {rhs4}", data=df_reg).fit()
    models["M4"] = m4

    for label, model in models.items():
        beta = model.params.get("ln_X", np.nan)
        pval = model.pvalues.get("ln_X", np.nan)
        adjr2 = model.rsquared_adj
        results.append([label, beta, pval, adjr2])

    summary = pd.DataFrame(results, columns=["Model", "β(ln_X)", "p(ln_X)", "Adj.R²"]).round(4)
    return models, summary

# --- Main Execution ---
try:
    df_mi = read_as_multiindex(DATA_FILE)
    st.success("✅ Dataset successfully loaded and formatted.")
except Exception as e:
    st.error(f"Data read failed: {e}")
    st.stop()

# --- Exploratory section ---
st.header("📊 Descriptive Statistics & Correlations")
flat_df = df_mi.copy()
flat_df.columns = [f"{a} [{b}]" for a, b in flat_df.columns]
num_df = flat_df.select_dtypes(include=np.number)
if num_df.empty:
    st.warning("No numeric data available.")
else:
    st.dataframe(num_df.describe().T)
    fig, ax = plt.subplots(figsize=(12, 6))
    sns.heatmap(num_df.corr(), cmap="coolwarm", center=0, ax=ax)
    ax.set_title("Correlation Heatmap")
    st.pyplot(fig)
    plt.close(fig)

# --- Regression analysis ---
st.header(f"🧮 Regression: GERD({X_YEAR}) → GDP({Y_YEAR})")
df_reg = build_pair_dataset(df_mi, X_YEAR, Y_YEAR)
if df_reg.empty:
    st.error("No valid data points found after cleaning. Check variable names and year alignment.")
    st.stop()

st.subheader("Preview of regression dataset")
st.dataframe(df_reg.head())

# --- Scatterplot ---
fig_sc, ax_sc = plt.subplots(figsize=(6, 5))
sns.regplot(x="ln_X", y="ln_Y", data=df_reg, scatter_kws={"alpha": 0.6}, ax=ax_sc)
ax_sc.set_xlabel(f"ln(GERD {X_YEAR})")
ax_sc.set_ylabel(f"ln(GDP {Y_YEAR})")
st.pyplot(fig_sc)
plt.close(fig_sc)

# --- Model execution and summary ---
models, summary = run_models(df_reg)
st.subheader("Model Comparison Table")
st.dataframe(summary)

fig_r2, ax_r2 = plt.subplots(figsize=(6, 4))
sns.barplot(x="Model", y="Adj.R²", data=summary, ax=ax_r2)
ax_r2.set_ylim(0, max(float(summary["Adj.R²"].max()), 0.1) * 1.1)
ax_r2.set_title("Adjusted R² across models")
st.pyplot(fig_r2)
plt.close(fig_r2)

# --- Expanded full model info ---
with st.expander("Full Regression Summaries"):
    for k, model in models.items():
        st.markdown(f"#### {k}")
        st.text(model.summary())

# --- Interpretations ---
st.markdown("""
### 🧩 Interpretation (2020 → 2023)
- **Model 1**: lnGERD(2020) → lnGDP(2023) 기본 탄력성 (기초 관계).
- **Model 2**: GDP per Capita, Labor Force(2023) 통제 - 혼란효과 검증.
- **Model 3**: 특허·연구인력·수출 변수 반영 - 매개효과 탐색.
- **Model 4**: 정부/기업 R&D 재원 상호작용 효과 (조절효과) 확인.
""")